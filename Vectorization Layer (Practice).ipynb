{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a8ca66a-656c-468e-83c0-8c9f3409e1cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_functions_lp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39menable_op_determinism()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcustom_functions_lp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfn\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextVectorization\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'custom_functions_lp'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Then Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Then run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536908c5-6b49-4754-91af-aab732854f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def make_text_vectorization_layer(train_ds,  max_tokens=None, \n",
    "                                  split='whitespace',\n",
    "                                  standardize=\"lower_and_strip_punctuation\",\n",
    "                                  output_mode=\"int\",\n",
    "                                  output_sequence_length=None,\n",
    "                                  ngrams=None, pad_to_max_tokens=False,\n",
    "                                  verbose=True,\n",
    "                                  **kwargs,\n",
    "                                 ):\n",
    "    # Build the text vectorization layer\n",
    "    text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        standardize=standardize, \n",
    "        output_mode=output_mode,\n",
    "        output_sequence_length=output_sequence_length,\n",
    "        **kwargs\n",
    "    )\n",
    "    # Get just the text from the training data\n",
    "    if isinstance(train_ds, (np.ndarray, list, tuple, pd.Series)):\n",
    "        ds_texts = train_ds\n",
    "    else:\n",
    "        try:\n",
    "            ds_texts = train_ds.map(lambda x, y: x )\n",
    "        except:\n",
    "            ds_texts = train_ds\n",
    "            \n",
    "    # Fit the layer on the training texts\n",
    "    text_vectorizer.adapt(ds_texts)\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        # Print the params\n",
    "        print( \"\\ntf.keras.layers.TextVectorization(\" )\n",
    "        config = text_vectorizer.get_config()\n",
    "        pprint(config,indent=4)\n",
    "        print(\")\")\n",
    "               \n",
    "    # SAVING VOCAB FOR LATER\n",
    "    # Getting list of vocab \n",
    "    vocab = text_vectorizer.get_vocabulary()\n",
    "    # Save dictionaries to look up words from ints \n",
    "    int_to_str  = {idx:word for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    return text_vectorizer, int_to_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7b2896-acd0-4ac9-9996-1a0e86201cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  id26305   \n",
       "1  id17569   \n",
       "2  id11008   \n",
       "3  id27763   \n",
       "4  id12958   \n",
       "\n",
       "                                                                                                                                                                                                                                      text  \\\n",
       "0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "1                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "2                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "3                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "4                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "  author  \n",
       "0    EAP  \n",
       "1    HPL  \n",
       "2    EAP  \n",
       "3    MWS  \n",
       "4    HPL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Data\n",
    "df = pd.read_csv(\"Data/spooky.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da7859e-a2e0-4cab-8a81-79b22b85e918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17718</th>\n",
       "      <td>I could have fancied, while I looked at it, that some eminent landscape painter had built it with his brush.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08973</th>\n",
       "      <td>The lids clenched themselves together as if in a spasm.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05267</th>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman never faints outright.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17513</th>\n",
       "      <td>For an item of news like this, it strikes us it was very coolly received.\"</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00393</th>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it seemed to me that its shaking was not altogether that of mirth.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "...                                                                                                                                                                                                                                          ...   \n",
       "id17718                                                                                                                             I could have fancied, while I looked at it, that some eminent landscape painter had built it with his brush.   \n",
       "id08973                                                                                                                                                                                  The lids clenched themselves together as if in a spasm.   \n",
       "id05267                                                                                                                                                                     Mais il faut agir that is to say, a Frenchman never faints outright.   \n",
       "id17513                                                                                                                                                               For an item of news like this, it strikes us it was very coolly received.\"   \n",
       "id00393                                                                                                                            He laid a gnarled claw on my shoulder, and it seemed to me that its shaking was not altogether that of mirth.   \n",
       "\n",
       "        author  \n",
       "id              \n",
       "id26305    EAP  \n",
       "id17569    HPL  \n",
       "id11008    EAP  \n",
       "id27763    MWS  \n",
       "id12958    HPL  \n",
       "...        ...  \n",
       "id17718    EAP  \n",
       "id08973    EAP  \n",
       "id05267    EAP  \n",
       "id17513    EAP  \n",
       "id00393    HPL  \n",
       "\n",
       "[19579 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025d6b66-81d2-4d4f-bf32-1f336f730c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  id26305   \n",
       "1  id17569   \n",
       "2  id11008   \n",
       "3  id27763   \n",
       "4  id12958   \n",
       "\n",
       "                                                                                                                                                                                                                                      text  \\\n",
       "0  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "1                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "2                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "3                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "4                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "  author  sequence_length  \n",
       "0    EAP               41  \n",
       "1    HPL               14  \n",
       "2    EAP               36  \n",
       "3    MWS               34  \n",
       "4    HPL               27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of each document - Using a lambda function\n",
    "\n",
    "df['sequence_length'] =df['text'].map( lambda x: len(x.split(\" \")))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22240b0c-517a-45f8-ae86-d4618cbeb4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.730477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.048353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>861.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence_length\n",
       "count     19579.000000\n",
       "mean         26.730477\n",
       "std          19.048353\n",
       "min           2.000000\n",
       "25%          15.000000\n",
       "50%          23.000000\n",
       "75%          34.000000\n",
       "max         861.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb5646-4634-47c1-9ade-47ee3046ac07",
   "metadata": {},
   "source": [
    "The range of sequence lengths is 2-861 words and the average is about 27 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8d2cbd-a24f-4e81-9fb6-5a28cd9f7d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se the RandomUnderSampler to balance the data based on the \"author\" column.\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "df[\"author\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d12795-abe1-47a4-887f-b7101f820b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    5635\n",
       "HPL    5635\n",
       "MWS    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RUS to reduce n to match minority group\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "df_ml,  _ = sampler.fit_resample(df, df['author'])\n",
    "df_ml['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6923d-0455-41a0-a20d-18aec9064101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the author strings to integers using the following mapping: EAP: 0, HPL: 1, MWS: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543fa8b9-0ae3-4b2f-8e72-46ed5e4203ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5635\n",
       "1    5635\n",
       "2    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a map for targets\n",
    "target_map = {'EAP':0,\n",
    "              'HPL':1,\n",
    "              'MWS':2}\n",
    "# DEfine y and apply the target_map\n",
    "y = df_ml['author'].map(target_map)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5ff27-3a59-4dff-a67f-6d19bd2623b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299a52d5-f329-4cd6-85ab-4b8f2412d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df_ml['text']\n",
    "y= df_ml['author']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba2812-b32f-460a-8c22-c23d1439bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LabelEncoder\n",
    "#encoder = LabelEncoder()\n",
    "# Fit and Transform the strings into integers\n",
    "#y = pd.Series(encoder.fit_transform(y))\n",
    "#y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8472247-1a03-4dbf-85f4-9add5cddbf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Dataset object\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd41013-1e4c-4ea2-b5c7-0f30fcd31e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data once\n",
    "ds = ds.shuffle(buffer_size=len(ds), reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "995576dd-ec58-47be-93b9-7e5ad6e35b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 11833 samples as training data\n",
      "Use 3381 samples as validation data\n",
      "The remaining 1691 samples will be used as test data.\n"
     ]
    }
   ],
   "source": [
    "# Determing how many samples for each split\n",
    "# Calculate the number of samples for training \n",
    "split_train = 0.7\n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "print(f\"Use {n_train_samples} samples as training data\")\n",
    "# Calculate the number of samples for validation\n",
    "split_val = 0.2\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "print(f\"Use {n_val_samples} samples as validation data\")\n",
    "# Test size is remainder\n",
    "split_test = 1 - (split_train + split_val)\n",
    "print(f\"The remaining {len(ds)- (n_train_samples+n_val_samples)} samples will be used as test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07541541-8183-4456-9480-b7fb176d24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .take to slice out the number of samples for training\n",
    "train_ds = ds.take(n_train_samples)\n",
    "# Skipover the training batches\n",
    "val_ds = ds.skip(n_train_samples)\n",
    "# Take .take to slice out the correct number of samples for validation\n",
    "val_ds = val_ds.take(n_val_samples)\n",
    "# Skip over all of the training + validation samples, the rest remain as samples for testing\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c4ae52-fe46-475c-91a3-f87049d41037",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling just the training data  \n",
    "train_ds  = train_ds.shuffle(buffer_size = len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef9415b9-4e9f-4af4-b5b5-9149b6eb5cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 370 training batches.\n",
      " There are 106 validation batches.\n",
      " There are 53 testing batches.\n"
     ]
    }
   ],
   "source": [
    "#  Setting the batch_size for all datasets\n",
    "BATCH_SIZE = 32\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7003f65d-5b77-4278-8df5-2dceed0926d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "array([b'This was a glorious winter.',\n",
       "       b'He had told her no more than he had told the public, but had left a long manuscript of \"technical matters\" as he said written in English, evidently in order to safeguard her from the peril of casual perusal.',\n",
       "       b'A nervous fever was the consequence; during which he was nursed by the daughter of a poor cottager, under whose roof he lodged.',\n",
       "       b\"I had before visited the manor houses and gentlemen's seats, and often found the inhabitants actuated by the purest benevolence, ready to lend their utmost aid for the welfare of their tenants.\",\n",
       "       b'The panic struck appeared of more injury, than disease and its natural concomitants.',\n",
       "       b'Each vessel in the mean time brought exhilarating tidings from Greece.',\n",
       "       b'Therein were written many things concerning the world of dream, and among them was lore of a golden valley and a sacred grove with temples, and a high wall pierced by a little bronze gate.',\n",
       "       b'There was a brief silence, and in that pause the scattered senses of poor Curtis Whateley began to knit back into a sort of continuity; so that he put his hands to his head with a moan.',\n",
       "       b'Me feered de bug what I keer for de bug?\"',\n",
       "       b'the, or, substituting the natural letters, where known, it reads thus: the tree thr?h the.',\n",
       "       b'I reply that I know nothing beyond what I saw.',\n",
       "       b'His design was to visit India, in the belief that he had in his knowledge of its various languages, and in the views he had taken of its society, the means of materially assisting the progress of European colonization and trade.',\n",
       "       b'The abode of the race whose scions are here inurned had once crowned the declivity which holds the tomb, but had long since fallen victim to the flames which sprang up from a disastrous stroke of lightning.',\n",
       "       b'And now he was equally resentful of awaking, for he had found his fabulous city after forty weary years.',\n",
       "       b\"Even when a cannon is fired over a corpse, and it rises before at least five or six days' immersion, it sinks again if let alone.'\",\n",
       "       b'There is nothing more lovely, to which the heart more yearns than a free spirited boy, gentle, brave, and generous.',\n",
       "       b'My beloved friends were alarmed nay, they expressed their alarm so anxiously, that I dared not pronounce the word plague, that hovered on my lips, lest they should construe my perturbed looks into a symptom, and see infection in my languor.',\n",
       "       b\"She and her brother were not so much interested in the house as was Archer's son Carrington, the present owner, with whom I talked after my experience.\",\n",
       "       b'There was no external door to the north wing, and it also had only one window to the east.',\n",
       "       b'But what mainly disturbed me was the idea that had perceptibly descended.',\n",
       "       b'His end had plainly forgotten his beginning, like the government of Trinculo.',\n",
       "       b'And if these were my sensations, who can describe those of Henry?',\n",
       "       b'In the chaos of sliding, shifting earth I clawed and floundered helplessly till the rain on my head steadied me and I saw that I had come to the surface in a familiar spot; a steep unforested place on the southwest slope of the mountain.',\n",
       "       b'In person, he is short and stout, with large, fat, blue eyes, sandy hair and whiskers, a wide but pleasing mouth, fine teeth, and I think a Roman nose.',\n",
       "       b'Detectives have questioned me, but what can I say?',\n",
       "       b'If he were vanquished, I should be a free man.',\n",
       "       b'What would happen on reanimation, and whether we could hope for a revival of mind and reason, West did not venture to predict.',\n",
       "       b'My rage was unbounded, yet my German sense forbade me to venture unprepared into an utterly black interior which might prove the lair of some indescribable marine monster or a labyrinth of passages from whose windings I could never extricate myself.',\n",
       "       b'Of its origin, apart from the erratic and unbelievable tales extorted from the captured members, absolutely nothing was to be discovered; hence the anxiety of the police for any antiquarian lore which might help them to place the frightful symbol, and through it track down the cult to its fountain head.',\n",
       "       b'\"As soon as the balloon quits the earth, it is subjected to the influence of many circumstances tending to create a difference in its weight; augmenting or diminishing its ascending power.',\n",
       "       b'She looked steadily on life and assumed its duties with courage and zeal.',\n",
       "       b'Besides, has he not had his full share of the blessings of mortality?'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accb8d47-1dc3-4551-ad5b-a01d10baed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequence length as a variable for future use\n",
    "SEQUENCE_LENGTH = 100\n",
    "# Define vectorizer layer. Use the custom function to build and fit the vectorizer before using it in model\n",
    "#sequence_vectorizer, vocab_lookup = fn.make_text_vectorization_layer(train_ds, output_mode='int', output_sequence_length = SEQUENCE_LENGTH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe92ea71-6f33-4ade-81cb-6a16c9423a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the layer on the training texts\n",
    "count_vectorizer.adapt(ds_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47f891f4-f297-4276-a5cb-5146cab85e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TextVectorization layer\n",
    "count_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"count\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e804ea1e-a4d6-4ed1-9bea-6216aa1bab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf.keras.layers.TextVectorization(\n",
      "{   'batch_input_shape': (None,),\n",
      "    'dtype': 'string',\n",
      "    'encoding': 'utf-8',\n",
      "    'idf_weights': None,\n",
      "    'max_tokens': None,\n",
      "    'name': 'text_vectorization_2',\n",
      "    'ngrams': None,\n",
      "    'output_mode': 'count',\n",
      "    'output_sequence_length': None,\n",
      "    'pad_to_max_tokens': False,\n",
      "    'ragged': False,\n",
      "    'sparse': False,\n",
      "    'split': 'whitespace',\n",
      "    'standardize': 'lower_and_strip_punctuation',\n",
      "    'trainable': True,\n",
      "    'vocabulary': None,\n",
      "    'vocabulary_size': 20975}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define vectorizer layer. Use the custom function to build and fit the vectorizer before using it in model\n",
    "count_vectorizer, count_lookup = make_text_vectorization_layer(train_ds, output_mode='count',\n",
    "                                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef381f3d-e9dd-4aa7-81d9-83afadb071cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20975"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the vocabulary\n",
    "len(count_vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727afa0-3cf0-427d-beaa-46d4d5eab7d2",
   "metadata": {},
   "source": [
    "The size of the vocabulary is 20975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c38f37d-f47a-44a2-9fad-3d5530a0c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20976"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=30\n",
    ")\n",
    "sequence_vectorizer.adapt(ds_texts)\n",
    "sequence_vectorizer.vocabulary_size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f0573c8-4e08-47fe-bd36-7e7844c99f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30), dtype=int64, numpy=\n",
       "array([[ 6345,     1,    28,    35,  6996, 13401,    18,     1,  6345,\n",
       "           57,     7,     1,    10,   833,  3862, 16160,   122,   521,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sequence of sample text with the sequence_vectorizer\n",
    "sequence= sequence_vectorizer(['Text Vectorization is an essential tool for converting text into a format that machine learning models can use.'])\n",
    "sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3339a02c-0e4c-4963-b1de-153fe2e82237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'the',\n",
       " 3: 'of',\n",
       " 4: 'and',\n",
       " 5: 'to',\n",
       " 6: 'i',\n",
       " 7: 'a',\n",
       " 8: 'in',\n",
       " 9: 'was',\n",
       " 10: 'that',\n",
       " 11: 'my',\n",
       " 12: 'it',\n",
       " 13: 'he',\n",
       " 14: 'had',\n",
       " 15: 'with',\n",
       " 16: 'his',\n",
       " 17: 'as',\n",
       " 18: 'for',\n",
       " 19: 'but',\n",
       " 20: 'which',\n",
       " 21: 'not',\n",
       " 22: 'me',\n",
       " 23: 'at',\n",
       " 24: 'from',\n",
       " 25: 'by',\n",
       " 26: 'on',\n",
       " 27: 'this',\n",
       " 28: 'is',\n",
       " 29: 'her',\n",
       " 30: 'be',\n",
       " 31: 'were',\n",
       " 32: 'have',\n",
       " 33: 'you',\n",
       " 34: 'all',\n",
       " 35: 'an',\n",
       " 36: 'we',\n",
       " 37: 'or',\n",
       " 38: 'no',\n",
       " 39: 'when',\n",
       " 40: 'him',\n",
       " 41: 'one',\n",
       " 42: 'so',\n",
       " 43: 'they',\n",
       " 44: 'been',\n",
       " 45: 'could',\n",
       " 46: 'would',\n",
       " 47: 'she',\n",
       " 48: 'there',\n",
       " 49: 'upon',\n",
       " 50: 'more',\n",
       " 51: 'its',\n",
       " 52: 'their',\n",
       " 53: 'now',\n",
       " 54: 'what',\n",
       " 55: 'some',\n",
       " 56: 'our',\n",
       " 57: 'into',\n",
       " 58: 'if',\n",
       " 59: 'them',\n",
       " 60: 'who',\n",
       " 61: 'are',\n",
       " 62: 'will',\n",
       " 63: 'than',\n",
       " 64: 'then',\n",
       " 65: 'only',\n",
       " 66: 'very',\n",
       " 67: 'up',\n",
       " 68: 'before',\n",
       " 69: 'man',\n",
       " 70: 'about',\n",
       " 71: 'even',\n",
       " 72: 'these',\n",
       " 73: 'out',\n",
       " 74: 'yet',\n",
       " 75: 'your',\n",
       " 76: 'time',\n",
       " 77: 'did',\n",
       " 78: 'any',\n",
       " 79: 'old',\n",
       " 80: 'said',\n",
       " 81: 'might',\n",
       " 82: 'like',\n",
       " 83: 'after',\n",
       " 84: 'over',\n",
       " 85: 'first',\n",
       " 86: 'night',\n",
       " 87: 'life',\n",
       " 88: 'through',\n",
       " 89: 'eyes',\n",
       " 90: 'us',\n",
       " 91: 'must',\n",
       " 92: 'do',\n",
       " 93: 'never',\n",
       " 94: 'most',\n",
       " 95: 'seemed',\n",
       " 96: 'should',\n",
       " 97: 'other',\n",
       " 98: 'found',\n",
       " 99: 'while',\n",
       " 100: 'made',\n",
       " 101: 'such',\n",
       " 102: 'saw',\n",
       " 103: 'great',\n",
       " 104: 'those',\n",
       " 105: 'still',\n",
       " 106: 'day',\n",
       " 107: 'where',\n",
       " 108: 'little',\n",
       " 109: 'every',\n",
       " 110: 'long',\n",
       " 111: 'again',\n",
       " 112: 'myself',\n",
       " 113: 'many',\n",
       " 114: 'down',\n",
       " 115: 'well',\n",
       " 116: 'has',\n",
       " 117: 'came',\n",
       " 118: 'how',\n",
       " 119: 'own',\n",
       " 120: 'much',\n",
       " 121: 'once',\n",
       " 122: 'can',\n",
       " 123: 'may',\n",
       " 124: 'two',\n",
       " 125: 'thought',\n",
       " 126: 'whose',\n",
       " 127: 'ever',\n",
       " 128: 'being',\n",
       " 129: 'death',\n",
       " 130: 'am',\n",
       " 131: 'things',\n",
       " 132: 'see',\n",
       " 133: 'men',\n",
       " 134: 'heard',\n",
       " 135: 'thus',\n",
       " 136: 'heart',\n",
       " 137: 'mind',\n",
       " 138: 'far',\n",
       " 139: 'too',\n",
       " 140: 'thing',\n",
       " 141: 'say',\n",
       " 142: 'know',\n",
       " 143: 'without',\n",
       " 144: 'left',\n",
       " 145: 'house',\n",
       " 146: 'shall',\n",
       " 147: 'though',\n",
       " 148: 'felt',\n",
       " 149: 'last',\n",
       " 150: 'here',\n",
       " 151: 'love',\n",
       " 152: 'come',\n",
       " 153: 'place',\n",
       " 154: 'away',\n",
       " 155: 'himself',\n",
       " 156: 'years',\n",
       " 157: 'became',\n",
       " 158: 'light',\n",
       " 159: 'few',\n",
       " 160: 'world',\n",
       " 161: 'however',\n",
       " 162: 'earth',\n",
       " 163: 'each',\n",
       " 164: 'nor',\n",
       " 165: 'indeed',\n",
       " 166: 'seen',\n",
       " 167: 'way',\n",
       " 168: 'room',\n",
       " 169: 'head',\n",
       " 170: 'words',\n",
       " 171: 'knew',\n",
       " 172: 'back',\n",
       " 173: 'door',\n",
       " 174: 'strange',\n",
       " 175: 'new',\n",
       " 176: 'whole',\n",
       " 177: 'hand',\n",
       " 178: 'human',\n",
       " 179: 'voice',\n",
       " 180: 'under',\n",
       " 181: 'same',\n",
       " 182: 'half',\n",
       " 183: 'fear',\n",
       " 184: 'let',\n",
       " 185: 'beyond',\n",
       " 186: 'nothing',\n",
       " 187: 'make',\n",
       " 188: 'having',\n",
       " 189: 'friend',\n",
       " 190: 'three',\n",
       " 191: 'soon',\n",
       " 192: 'raymond',\n",
       " 193: 'father',\n",
       " 194: 'off',\n",
       " 195: 'good',\n",
       " 196: 'during',\n",
       " 197: 'among',\n",
       " 198: 'length',\n",
       " 199: 'part',\n",
       " 200: 'moment',\n",
       " 201: 'within',\n",
       " 202: 'nature',\n",
       " 203: 'less',\n",
       " 204: 'alone',\n",
       " 205: 'looked',\n",
       " 206: 'since',\n",
       " 207: 'almost',\n",
       " 208: 'small',\n",
       " 209: 'near',\n",
       " 210: 'gave',\n",
       " 211: 'around',\n",
       " 212: 'something',\n",
       " 213: 'sea',\n",
       " 214: 'another',\n",
       " 215: 'told',\n",
       " 216: 'face',\n",
       " 217: 'city',\n",
       " 218: 'appeared',\n",
       " 219: 'went',\n",
       " 220: 'passed',\n",
       " 221: 'air',\n",
       " 222: 'young',\n",
       " 223: 'whom',\n",
       " 224: 'find',\n",
       " 225: 'dark',\n",
       " 226: 'took',\n",
       " 227: 'soul',\n",
       " 228: 'certain',\n",
       " 229: 'although',\n",
       " 230: 'full',\n",
       " 231: 'tell',\n",
       " 232: 'high',\n",
       " 233: 'days',\n",
       " 234: 'also',\n",
       " 235: 'think',\n",
       " 236: 'horror',\n",
       " 237: 'take',\n",
       " 238: 'began',\n",
       " 239: 'above',\n",
       " 240: 'just',\n",
       " 241: 'end',\n",
       " 242: 'body',\n",
       " 243: 'lay',\n",
       " 244: 'dead',\n",
       " 245: 'course',\n",
       " 246: 'black',\n",
       " 247: 'why',\n",
       " 248: 'hope',\n",
       " 249: 'form',\n",
       " 250: 'street',\n",
       " 251: 'o',\n",
       " 252: 'go',\n",
       " 253: 'turned',\n",
       " 254: 'kind',\n",
       " 255: 'towards',\n",
       " 256: 'itself',\n",
       " 257: 'open',\n",
       " 258: 'spirit',\n",
       " 259: 'cannot',\n",
       " 260: 'mr',\n",
       " 261: 'least',\n",
       " 262: 'because',\n",
       " 263: 'water',\n",
       " 264: 'scene',\n",
       " 265: 'point',\n",
       " 266: 'often',\n",
       " 267: 'between',\n",
       " 268: 'sometimes',\n",
       " 269: 'look',\n",
       " 270: 'lost',\n",
       " 271: 'known',\n",
       " 272: 'always',\n",
       " 273: 'until',\n",
       " 274: 'name',\n",
       " 275: 'hours',\n",
       " 276: 'deep',\n",
       " 277: 'ancient',\n",
       " 278: 'feet',\n",
       " 279: 'taken',\n",
       " 280: 'return',\n",
       " 281: 'perhaps',\n",
       " 282: 'against',\n",
       " 283: 'morning',\n",
       " 284: 'white',\n",
       " 285: 'rather',\n",
       " 286: 'hands',\n",
       " 287: 'dream',\n",
       " 288: 'sun',\n",
       " 289: 'present',\n",
       " 290: 'home',\n",
       " 291: 'eye',\n",
       " 292: 'town',\n",
       " 293: 'spoke',\n",
       " 294: 'idea',\n",
       " 295: 'brought',\n",
       " 296: 'both',\n",
       " 297: 'power',\n",
       " 298: 'called',\n",
       " 299: 'stood',\n",
       " 300: 'sight',\n",
       " 301: 'side',\n",
       " 302: 'right',\n",
       " 303: 'put',\n",
       " 304: 'people',\n",
       " 305: 'moon',\n",
       " 306: 'fell',\n",
       " 307: 'thousand',\n",
       " 308: 'speak',\n",
       " 309: 'poor',\n",
       " 310: 'perdita',\n",
       " 311: 'others',\n",
       " 312: 'country',\n",
       " 313: 'object',\n",
       " 314: 'matter',\n",
       " 315: 'terrible',\n",
       " 316: 'floor',\n",
       " 317: 'done',\n",
       " 318: 'change',\n",
       " 319: 'beauty',\n",
       " 320: 'times',\n",
       " 321: 'several',\n",
       " 322: 'person',\n",
       " 323: 'nearly',\n",
       " 324: 'sound',\n",
       " 325: 'grew',\n",
       " 326: 'feel',\n",
       " 327: 'truth',\n",
       " 328: 'means',\n",
       " 329: 'manner',\n",
       " 330: 'give',\n",
       " 331: 'evil',\n",
       " 332: 'entered',\n",
       " 333: 'dreams',\n",
       " 334: 'continued',\n",
       " 335: 'believe',\n",
       " 336: 'west',\n",
       " 337: 'set',\n",
       " 338: 'better',\n",
       " 339: 'become',\n",
       " 340: 'till',\n",
       " 341: 'quite',\n",
       " 342: 'hour',\n",
       " 343: 'true',\n",
       " 344: 'themselves',\n",
       " 345: 'stone',\n",
       " 346: 'sleep',\n",
       " 347: 'read',\n",
       " 348: 'past',\n",
       " 349: 'gone',\n",
       " 350: 'work',\n",
       " 351: 'tears',\n",
       " 352: 'suddenly',\n",
       " 353: 'trees',\n",
       " 354: 'state',\n",
       " 355: 'happy',\n",
       " 356: 'family',\n",
       " 357: 'fact',\n",
       " 358: 'despair',\n",
       " 359: 'case',\n",
       " 360: 'wild',\n",
       " 361: 'second',\n",
       " 362: 'general',\n",
       " 363: 'longer',\n",
       " 364: 'dear',\n",
       " 365: 'possible',\n",
       " 366: 'none',\n",
       " 367: 'adrian',\n",
       " 368: 'thoughts',\n",
       " 369: 'doubt',\n",
       " 370: 'died',\n",
       " 371: 'wonder',\n",
       " 372: 'led',\n",
       " 373: 'happiness',\n",
       " 374: 'de',\n",
       " 375: 'close',\n",
       " 376: 'window',\n",
       " 377: 'walls',\n",
       " 378: 'next',\n",
       " 379: 'ground',\n",
       " 380: 'gentle',\n",
       " 381: 'wish',\n",
       " 382: 'secret',\n",
       " 383: 'remained',\n",
       " 384: 'countenance',\n",
       " 385: 'sense',\n",
       " 386: 'reason',\n",
       " 387: 'idris',\n",
       " 388: 'child',\n",
       " 389: 'already',\n",
       " 390: 'wind',\n",
       " 391: 'god',\n",
       " 392: 'existence',\n",
       " 393: 'evening',\n",
       " 394: 'enough',\n",
       " 395: 'blood',\n",
       " 396: 'word',\n",
       " 397: 'together',\n",
       " 398: 'mother',\n",
       " 399: 'low',\n",
       " 400: 'friends',\n",
       " 401: 'feelings',\n",
       " 402: 'beneath',\n",
       " 403: 'age',\n",
       " 404: 'unknown',\n",
       " 405: 'rest',\n",
       " 406: 'replied',\n",
       " 407: 'large',\n",
       " 408: 'get',\n",
       " 409: 'five',\n",
       " 410: 'character',\n",
       " 411: 'attention',\n",
       " 412: 'appearance',\n",
       " 413: 'wall',\n",
       " 414: 'space',\n",
       " 415: 'sky',\n",
       " 416: 'oh',\n",
       " 417: 'lips',\n",
       " 418: 'hideous',\n",
       " 419: 'feeling',\n",
       " 420: 'england',\n",
       " 421: 'either',\n",
       " 422: 'best',\n",
       " 423: 'behind',\n",
       " 424: 'windows',\n",
       " 425: 'looking',\n",
       " 426: 'late',\n",
       " 427: 'land',\n",
       " 428: 'immediately',\n",
       " 429: 'sat',\n",
       " 430: 'held',\n",
       " 431: 'fellow',\n",
       " 432: 'children',\n",
       " 433: 'therefore',\n",
       " 434: 'period',\n",
       " 435: 'hear',\n",
       " 436: 'given',\n",
       " 437: 'filled',\n",
       " 438: 'along',\n",
       " 439: 'account',\n",
       " 440: 'spot',\n",
       " 441: 'river',\n",
       " 442: 'misery',\n",
       " 443: 'living',\n",
       " 444: 'chamber',\n",
       " 445: 'toward',\n",
       " 446: 'joy',\n",
       " 447: 'imagination',\n",
       " 448: 'short',\n",
       " 449: 'reached',\n",
       " 450: 'cold',\n",
       " 451: 'returned',\n",
       " 452: 'natural',\n",
       " 453: 'mad',\n",
       " 454: 'loved',\n",
       " 455: 'interest',\n",
       " 456: 'followed',\n",
       " 457: 'view',\n",
       " 458: 'sure',\n",
       " 459: 'steps',\n",
       " 460: 'leave',\n",
       " 461: 'knowledge',\n",
       " 462: 'four',\n",
       " 463: 'care',\n",
       " 464: 'vast',\n",
       " 465: 'tried',\n",
       " 466: 'sir',\n",
       " 467: 'neither',\n",
       " 468: 'herself',\n",
       " 469: 'fire',\n",
       " 470: 'early',\n",
       " 471: 'cast',\n",
       " 472: 'arms',\n",
       " 473: 'affection',\n",
       " 474: 'terror',\n",
       " 475: 'question',\n",
       " 476: 'greater',\n",
       " 477: 'gods',\n",
       " 478: 'escape',\n",
       " 479: 'distance',\n",
       " 480: 'youth',\n",
       " 481: 'silence',\n",
       " 482: 'observed',\n",
       " 483: 'north',\n",
       " 484: 'months',\n",
       " 485: 'latter',\n",
       " 486: 'kept',\n",
       " 487: 'bed',\n",
       " 488: 'table',\n",
       " 489: 'memory',\n",
       " 490: 'live',\n",
       " 491: 'letter',\n",
       " 492: 'ill',\n",
       " 493: 'discovered',\n",
       " 494: 'die',\n",
       " 495: 'year',\n",
       " 496: 'self',\n",
       " 497: 'necessary',\n",
       " 498: 'mine',\n",
       " 499: 'hill',\n",
       " 500: 'darkness',\n",
       " 501: 'common',\n",
       " 502: 'coming',\n",
       " 503: 'circumstances',\n",
       " 504: 'caused',\n",
       " 505: 'call',\n",
       " 506: 'beautiful',\n",
       " 507: 'arm',\n",
       " 508: 'across',\n",
       " 509: 'subject',\n",
       " 510: 'really',\n",
       " 511: 'purpose',\n",
       " 512: 'possessed',\n",
       " 513: 'merely',\n",
       " 514: 'heavy',\n",
       " 515: 'heaven',\n",
       " 516: 'green',\n",
       " 517: 'forth',\n",
       " 518: 'dr',\n",
       " 519: 'cause',\n",
       " 520: 'born',\n",
       " 521: 'use',\n",
       " 522: 'thy',\n",
       " 523: 'thou',\n",
       " 524: 'sought',\n",
       " 525: 'six',\n",
       " 526: 'remember',\n",
       " 527: 'received',\n",
       " 528: 'grief',\n",
       " 529: 'various',\n",
       " 530: 'threw',\n",
       " 531: 'save',\n",
       " 532: 'portion',\n",
       " 533: 'pleasure',\n",
       " 534: 'met',\n",
       " 535: 'later',\n",
       " 536: 'excited',\n",
       " 537: 'woman',\n",
       " 538: 'strength',\n",
       " 539: 'scarcely',\n",
       " 540: 'mere',\n",
       " 541: 'line',\n",
       " 542: 'houses',\n",
       " 543: 'formed',\n",
       " 544: 'finally',\n",
       " 545: 'drew',\n",
       " 546: 'beheld',\n",
       " 547: 'ye',\n",
       " 548: 'pain',\n",
       " 549: 'opened',\n",
       " 550: 'native',\n",
       " 551: 'entirely',\n",
       " 552: 'delight',\n",
       " 553: 'cottage',\n",
       " 554: 'wide',\n",
       " 555: 'valley',\n",
       " 556: 'somewhat',\n",
       " 557: 'peculiar',\n",
       " 558: 'instant',\n",
       " 559: 'fancy',\n",
       " 560: 'usual',\n",
       " 561: 'tale',\n",
       " 562: 'streets',\n",
       " 563: 'red',\n",
       " 564: 'outside',\n",
       " 565: 'london',\n",
       " 566: 'lady',\n",
       " 567: 'especially',\n",
       " 568: 'distant',\n",
       " 569: 'degree',\n",
       " 570: 'corpse',\n",
       " 571: 'box',\n",
       " 572: 'wished',\n",
       " 573: 'visible',\n",
       " 574: 'sounds',\n",
       " 575: 'sister',\n",
       " 576: 'rose',\n",
       " 577: 'road',\n",
       " 578: 'got',\n",
       " 579: 'cut',\n",
       " 580: 'calm',\n",
       " 581: 'broken',\n",
       " 582: 'below',\n",
       " 583: 'visit',\n",
       " 584: 'twenty',\n",
       " 585: 'turn',\n",
       " 586: 'ten',\n",
       " 587: 'silent',\n",
       " 588: 'shadow',\n",
       " 589: 'placed',\n",
       " 590: 'hold',\n",
       " 591: 'does',\n",
       " 592: 'book',\n",
       " 593: 'blue',\n",
       " 594: 'asked',\n",
       " 595: 'arrived',\n",
       " 596: 'arose',\n",
       " 597: 'uncle',\n",
       " 598: 'simple',\n",
       " 599: 'round',\n",
       " 600: 'resolved',\n",
       " 601: 'madness',\n",
       " 602: 'lovely',\n",
       " 603: 'lived',\n",
       " 604: 'impossible',\n",
       " 605: 'hills',\n",
       " 606: 'grave',\n",
       " 607: 'faint',\n",
       " 608: 'expression',\n",
       " 609: 'difficulty',\n",
       " 610: 'curious',\n",
       " 611: 'creatures',\n",
       " 612: 'companion',\n",
       " 613: 'closed',\n",
       " 614: 'castle',\n",
       " 615: 'altogether',\n",
       " 616: 'top',\n",
       " 617: 'sweet',\n",
       " 618: 'south',\n",
       " 619: 'horrible',\n",
       " 620: 'fate',\n",
       " 621: 'bring',\n",
       " 622: 'boat',\n",
       " 623: 'spent',\n",
       " 624: 'presence',\n",
       " 625: 'paper',\n",
       " 626: 'mountain',\n",
       " 627: 'keep',\n",
       " 628: 'ice',\n",
       " 629: 'hair',\n",
       " 630: 'east',\n",
       " 631: 'clear',\n",
       " 632: 'books',\n",
       " 633: 'beloved',\n",
       " 634: 'yes',\n",
       " 635: 'whether',\n",
       " 636: 'son',\n",
       " 637: 'slight',\n",
       " 638: 'real',\n",
       " 639: 'odd',\n",
       " 640: 'free',\n",
       " 641: 'force',\n",
       " 642: 'else',\n",
       " 643: 'deserted',\n",
       " 644: 'dared',\n",
       " 645: 'wife',\n",
       " 646: 'want',\n",
       " 647: 'sorrow',\n",
       " 648: 'narrow',\n",
       " 649: 'hardly',\n",
       " 650: 'fully',\n",
       " 651: 'figure',\n",
       " 652: 'events',\n",
       " 653: 'easily',\n",
       " 654: 'creature',\n",
       " 655: 'bore',\n",
       " 656: 'atmosphere',\n",
       " 657: 'ago',\n",
       " 658: 'talked',\n",
       " 659: 'proceeded',\n",
       " 660: 'position',\n",
       " 661: 'party',\n",
       " 662: 'order',\n",
       " 663: 'ocean',\n",
       " 664: 'occurred',\n",
       " 665: 'music',\n",
       " 666: 'mountains',\n",
       " 667: 'marble',\n",
       " 668: 'lord',\n",
       " 669: 'future',\n",
       " 670: 'english',\n",
       " 671: 'effect',\n",
       " 672: 'danger',\n",
       " 673: 'cried',\n",
       " 674: 'changed',\n",
       " 675: 'anything',\n",
       " 676: 'tomb',\n",
       " 677: 'stars',\n",
       " 678: 'singular',\n",
       " 679: 'single',\n",
       " 680: 'shore',\n",
       " 681: 'seized',\n",
       " 682: 'says',\n",
       " 683: 'reality',\n",
       " 684: 'public',\n",
       " 685: 'pale',\n",
       " 686: 'minutes',\n",
       " 687: 'hard',\n",
       " 688: 'grey',\n",
       " 689: 'going',\n",
       " 690: 'frightful',\n",
       " 691: 'fresh',\n",
       " 692: 'forest',\n",
       " 693: 'fallen',\n",
       " 694: 'expected',\n",
       " 695: 'direction',\n",
       " 696: 'courage',\n",
       " 697: 'brain',\n",
       " 698: 'apparently',\n",
       " 699: 'vain',\n",
       " 700: 'thrown',\n",
       " 701: 'thee',\n",
       " 702: 'struck',\n",
       " 703: 'step',\n",
       " 704: 'society',\n",
       " 705: 'progress',\n",
       " 706: 'ones',\n",
       " 707: 'miles',\n",
       " 708: 'hopes',\n",
       " 709: 'forgotten',\n",
       " 710: 'foot',\n",
       " 711: 'elizabeth',\n",
       " 712: 'different',\n",
       " 713: 'condition',\n",
       " 714: 'able',\n",
       " 715: 'windsor',\n",
       " 716: 'utterly',\n",
       " 717: 'story',\n",
       " 718: 'st',\n",
       " 719: 'passion',\n",
       " 720: 'moved',\n",
       " 721: 'influence',\n",
       " 722: 'hidden',\n",
       " 723: 'golden',\n",
       " 724: 'gilman',\n",
       " 725: 'former',\n",
       " 726: 'fears',\n",
       " 727: 'dare',\n",
       " 728: 'boy',\n",
       " 729: 'beings',\n",
       " 730: 'approached',\n",
       " 731: 'absence',\n",
       " 732: 'whilst',\n",
       " 733: 'third',\n",
       " 734: 'strong',\n",
       " 735: 'plague',\n",
       " 736: 'persons',\n",
       " 737: 'perceived',\n",
       " 738: 'passage',\n",
       " 739: 'objects',\n",
       " 740: 'motion',\n",
       " 741: 'miserable',\n",
       " 742: 'mean',\n",
       " 743: 'making',\n",
       " 744: 'journey',\n",
       " 745: 'girl',\n",
       " 746: 'frame',\n",
       " 747: 'fine',\n",
       " 748: 'describe',\n",
       " 749: 'art',\n",
       " 750: 'watched',\n",
       " 751: 'walked',\n",
       " 752: 'tree',\n",
       " 753: 'task',\n",
       " 754: 'taking',\n",
       " 755: 'storm',\n",
       " 756: 'sort',\n",
       " 757: 'ship',\n",
       " 758: 'seek',\n",
       " 759: 'rise',\n",
       " 760: 'remote',\n",
       " 761: 'rain',\n",
       " 762: 'quickly',\n",
       " 763: 'path',\n",
       " 764: 'pass',\n",
       " 765: 'midnight',\n",
       " 766: 'main',\n",
       " 767: 'health',\n",
       " 768: 'fall',\n",
       " 769: 'exceedingly',\n",
       " 770: 'evidently',\n",
       " 771: 'curiosity',\n",
       " 772: 'besides',\n",
       " 773: 'alive',\n",
       " 774: 'action',\n",
       " 775: 'act',\n",
       " 776: 'wood',\n",
       " 777: 'winter',\n",
       " 778: 'understand',\n",
       " 779: 'summer',\n",
       " 780: 'sudden',\n",
       " 781: 'rendered',\n",
       " 782: 'places',\n",
       " 783: 'peace',\n",
       " 784: 'monstrous',\n",
       " 785: 'listened',\n",
       " 786: 'immediate',\n",
       " 787: 'hung',\n",
       " 788: 'height',\n",
       " 789: 'gold',\n",
       " 790: 'fearful',\n",
       " 791: 'faces',\n",
       " 792: 'dont',\n",
       " 793: 'conversation',\n",
       " 794: 'carried',\n",
       " 795: 'arkham',\n",
       " 796: 'vague',\n",
       " 797: 'surface',\n",
       " 798: 'smile',\n",
       " 799: 'slowly',\n",
       " 800: 'situation',\n",
       " 801: 'remain',\n",
       " 802: 'reach',\n",
       " 803: 'ran',\n",
       " 804: 'queer',\n",
       " 805: 'need',\n",
       " 806: 'mouth',\n",
       " 807: 'mighty',\n",
       " 808: 'mentioned',\n",
       " 809: 'madame',\n",
       " 810: 'king',\n",
       " 811: 'hundred',\n",
       " 812: 'help',\n",
       " 813: 'extreme',\n",
       " 814: 'extent',\n",
       " 815: 'ears',\n",
       " 816: 'disease',\n",
       " 817: 'daughter',\n",
       " 818: 'corner',\n",
       " 819: 'company',\n",
       " 820: 'certainly',\n",
       " 821: 'behold',\n",
       " 822: 'balloon',\n",
       " 823: 'appear',\n",
       " 824: 'yourself',\n",
       " 825: 'village',\n",
       " 826: 'thin',\n",
       " 827: 'talk',\n",
       " 828: 'supposed',\n",
       " 829: 'shewed',\n",
       " 830: 'senses',\n",
       " 831: 'seems',\n",
       " 832: 'promise',\n",
       " 833: 'machine',\n",
       " 834: 'listen',\n",
       " 835: 'language',\n",
       " 836: 'glass',\n",
       " 837: 'features',\n",
       " 838: 'fathers',\n",
       " 839: 'familiar',\n",
       " 840: 'desire',\n",
       " 841: 'car',\n",
       " 842: 'business',\n",
       " 843: 'alas',\n",
       " 844: 'weight',\n",
       " 845: 'violent',\n",
       " 846: 'sympathy',\n",
       " 847: 'started',\n",
       " 848: 'sinister',\n",
       " 849: 'science',\n",
       " 850: 'result',\n",
       " 851: 'quiet',\n",
       " 852: 'prepared',\n",
       " 853: 'paused',\n",
       " 854: 'nose',\n",
       " 855: 'noble',\n",
       " 856: 'leaving',\n",
       " 857: 'innsmouth',\n",
       " 858: 'image',\n",
       " 859: 'glory',\n",
       " 860: 'forever',\n",
       " 861: 'determined',\n",
       " 862: 'clouds',\n",
       " 863: 'building',\n",
       " 864: 'attempt',\n",
       " 865: 'agony',\n",
       " 866: 'visited',\n",
       " 867: 'thick',\n",
       " 868: 'sufficient',\n",
       " 869: 'suffered',\n",
       " 870: 'success',\n",
       " 871: 'succeeded',\n",
       " 872: 'spring',\n",
       " 873: 'spread',\n",
       " 874: 'solitude',\n",
       " 875: 'sole',\n",
       " 876: 'reflection',\n",
       " 877: 'pocket',\n",
       " 878: 'occupied',\n",
       " 879: 'nervous',\n",
       " 880: 'hall',\n",
       " 881: 'forms',\n",
       " 882: 'follow',\n",
       " 883: 'flowers',\n",
       " 884: 'fever',\n",
       " 885: 'except',\n",
       " 886: 'dupin',\n",
       " 887: 'despite',\n",
       " 888: 'considered',\n",
       " 889: 'conduct',\n",
       " 890: 'big',\n",
       " 891: 'apparent',\n",
       " 892: 'woods',\n",
       " 893: 'waters',\n",
       " 894: 'utter',\n",
       " 895: 'trace',\n",
       " 896: 'roof',\n",
       " 897: 'relief',\n",
       " 898: 'powers',\n",
       " 899: 'ordinary',\n",
       " 900: 'notice',\n",
       " 901: 'melancholy',\n",
       " 902: 'marked',\n",
       " 903: 'm',\n",
       " 904: 'island',\n",
       " 905: 'ideas',\n",
       " 906: 'forced',\n",
       " 907: 'feared',\n",
       " 908: 'fashion',\n",
       " 909: 'expressed',\n",
       " 910: 'experienced',\n",
       " 911: 'crowd',\n",
       " 912: 'covered',\n",
       " 913: 'concerning',\n",
       " 914: 'century',\n",
       " 915: 'carefully',\n",
       " 916: 'bodies',\n",
       " 917: 'apartment',\n",
       " 918: 'aid',\n",
       " 919: 'accursed',\n",
       " 920: 'watch',\n",
       " 921: 'used',\n",
       " 922: 'unable',\n",
       " 923: 'temple',\n",
       " 924: 'tall',\n",
       " 925: 'tales',\n",
       " 926: 'study',\n",
       " 927: 'soft',\n",
       " 928: 'rock',\n",
       " 929: 'remembered',\n",
       " 930: 'recall',\n",
       " 931: 'perceive',\n",
       " 932: 'original',\n",
       " 933: 'mystery',\n",
       " 934: 'minute',\n",
       " 935: 'mental',\n",
       " 936: 'meet',\n",
       " 937: 'limbs',\n",
       " 938: 'learned',\n",
       " 939: 'lake',\n",
       " 940: 'key',\n",
       " 941: 'heavens',\n",
       " 942: 'forward',\n",
       " 943: 'enter',\n",
       " 944: 'enemy',\n",
       " 945: 'discovery',\n",
       " 946: 'destruction',\n",
       " 947: 'bitter',\n",
       " 948: 'bent',\n",
       " 949: 'anxiety',\n",
       " 950: 'answer',\n",
       " 951: 'amidst',\n",
       " 952: 'wholly',\n",
       " 953: 'week',\n",
       " 954: 'vision',\n",
       " 955: 'stranger',\n",
       " 956: 'spirits',\n",
       " 957: 'shut',\n",
       " 958: 'seem',\n",
       " 959: 'regard',\n",
       " 960: 'professor',\n",
       " 961: 'probably',\n",
       " 962: 'presented',\n",
       " 963: 'noticed',\n",
       " 964: 'material',\n",
       " 965: 'impression',\n",
       " 966: 'haunted',\n",
       " 967: 'greek',\n",
       " 968: 'greatest',\n",
       " 969: 'glance',\n",
       " 970: 'ghastly',\n",
       " 971: 'gentleman',\n",
       " 972: 'fled',\n",
       " 973: 'farewell',\n",
       " 974: 'fair',\n",
       " 975: 'dying',\n",
       " 976: 'dwelt',\n",
       " 977: 'duty',\n",
       " 978: 'departure',\n",
       " 979: 'degrees',\n",
       " 980: 'brother',\n",
       " 981: 'beside',\n",
       " 982: 'bear',\n",
       " 983: 'aside',\n",
       " 984: 'aout',\n",
       " 985: 'weak',\n",
       " 986: 'walk',\n",
       " 987: 'try',\n",
       " 988: 'sufficiently',\n",
       " 989: 'servant',\n",
       " 990: 'sent',\n",
       " 991: 'satisfied',\n",
       " 992: 'respect',\n",
       " 993: 'region',\n",
       " 994: 'produced',\n",
       " 995: 'plain',\n",
       " 996: 'permitted',\n",
       " 997: 'palace',\n",
       " 998: 'painful',\n",
       " 999: 'oclock',\n",
       " ...}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of vocab\n",
    "vocab = sequence_vectorizer.get_vocabulary()\n",
    "int_to_str = {idx: word for idx, word in enumerate(vocab)}\n",
    "int_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21a73174-b811-4d83-98cc-7d16c5ac6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'occasion'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occasion is the 1000th term\n",
    "int_to_str[1000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f48b7-da99-4db0-8da4-8cdd5c49e2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c1507-b045-44d3-ba6c-5532af5adce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688d11b-4d3a-4663-ae2b-56eca791a3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c443f6c-3c71-4ffe-933d-29e27972d81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea60e9-b4b4-46e6-a053-532323584f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f0ec0-8e93-4886-8ea6-1a683ad171f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570612fb-ad70-4665-b48c-e3652f948f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071664f4-1536-42ab-9af8-6f158272886f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06764e-7842-4e0b-9160-132bfe5f7726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade55c2-2f17-4278-bd5a-8673009e1063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2a972-95bc-4c1d-988c-fe2a39ee879f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6209d-33a4-4459-b71a-f69892dd0eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af080c4-84da-4c7d-828e-6c22a14b4a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c36bc-6353-452d-aaac-75d923b9af90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dece29-fadf-45ba-961a-ac4d83fa346d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6d796-a3e6-44e0-85a0-c64cdd22db77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2073a0b-831e-4bb2-90f8-6058732c07c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4d93e-d75b-4855-9d66-6cf10a5d4146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05627c-33a8-48ba-92ef-1915a30a1f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
